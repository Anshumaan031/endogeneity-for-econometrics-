{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import linearmodels.iv.model as lm\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "n = 10000\n",
    "X1 = np.random.randn(n)  # Exogenous variable\n",
    "instrument = np.random.randn(n)  # Instrument for X2\n",
    "epsilon = np.random.randn(n)  # Error term\n",
    "\n",
    "# Assume X2 is endogenous, correlated with epsilon\n",
    "X2 = 0.5 * instrument + 0.5 * epsilon   #reduced form of the equation \n",
    "\n",
    "# Generate outcome variable Y\n",
    "beta0, beta1, beta2 = 1, 2, 3   #parameter estimates \n",
    "Y = beta0 + beta1 * X1 + beta2 * X2 + epsilon     #equation after adding the instrumental variable to the sructural form \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.280e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Sep 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:42:00</td>     <th>  Log-Likelihood:    </th> <td> -10546.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>2.110e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9997</td>      <th>  BIC:               </th> <td>2.112e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9870</td> <td>    0.007</td> <td>  142.072</td> <td> 0.000</td> <td>    0.973</td> <td>    1.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.0176</td> <td>    0.007</td> <td>  291.370</td> <td> 0.000</td> <td>    2.004</td> <td>    2.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.9903</td> <td>    0.010</td> <td>  409.933</td> <td> 0.000</td> <td>    3.971</td> <td>    4.009</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.152</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.927</td> <th>  Jarque-Bera (JB):  </th> <td>   0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.006</td> <th>  Prob(JB):          </th> <td>   0.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.014</td> <th>  Cond. No.          </th> <td>    1.41</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.962   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.962   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 1.280e+05   \\\\\n",
       "\\textbf{Date:}             & Fri, 01 Sep 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     15:42:00     & \\textbf{  Log-Likelihood:    } &   -10546.   \\\\\n",
       "\\textbf{No. Observations:} &       10000      & \\textbf{  AIC:               } & 2.110e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        9997      & \\textbf{  BIC:               } & 2.112e+04   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.9870  &        0.007     &   142.072  &         0.000        &        0.973    &        1.001     \\\\\n",
       "\\textbf{x1}    &       2.0176  &        0.007     &   291.370  &         0.000        &        2.004    &        2.031     \\\\\n",
       "\\textbf{x2}    &       3.9903  &        0.010     &   409.933  &         0.000        &        3.971    &        4.009     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.152 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.927 & \\textbf{  Jarque-Bera (JB):  } &    0.131  \\\\\n",
       "\\textbf{Skew:}          &  0.006 & \\textbf{  Prob(JB):          } &    0.937  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.014 & \\textbf{  Cond. No.          } &     1.41  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.962\n",
       "Model:                            OLS   Adj. R-squared:                  0.962\n",
       "Method:                 Least Squares   F-statistic:                 1.280e+05\n",
       "Date:                Fri, 01 Sep 2023   Prob (F-statistic):               0.00\n",
       "Time:                        15:42:00   Log-Likelihood:                -10546.\n",
       "No. Observations:               10000   AIC:                         2.110e+04\n",
       "Df Residuals:                    9997   BIC:                         2.112e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9870      0.007    142.072      0.000       0.973       1.001\n",
       "x1             2.0176      0.007    291.370      0.000       2.004       2.031\n",
       "x2             3.9903      0.010    409.933      0.000       3.971       4.009\n",
       "==============================================================================\n",
       "Omnibus:                        0.152   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.927   Jarque-Bera (JB):                0.131\n",
       "Skew:                           0.006   Prob(JB):                        0.937\n",
       "Kurtosis:                       3.014   Cond. No.                         1.41\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Regression\n",
    "X_orig = sm.add_constant(np.column_stack((X1, X2)))  #Add a column of ones to an array (in this case adding columns X1 and X2)\n",
    "model_original = sm.OLS(Y, X_orig).fit()   #estimating regression parameters using OLS using endog and exog varaibles \n",
    "orig_coef = model_original.params[2]\n",
    "model_original.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Hausman test of exogeneity\n",
      "H0: All endogenous variables are exogenous\n",
      "Statistic: 4571.5444\n",
      "P-value: 0.0000\n",
      "Distributed: F(1,9997)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Test statistic is difference between sum of squared OLS and sum of\\nsquared IV residuals where each set of residuals has been projected\\nonto the set of instruments in the IV model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use linearmodels package to do 2SLS and generate test result as well\n",
    "mlr2 = lm.IV2SLS(dependent=Y, exog=X1, endog=X2, instruments=instrument).fit(cov_type=\"homoskedastic\", debiased=True) #Estimation of IV models using two-stage least squares\n",
    "print(mlr2.wu_hausman())   #using hausman test to test for endogeneity\n",
    "\n",
    "\"\"\"Test statistic is difference between sum of squared OLS and sum of\n",
    "squared IV residuals where each set of residuals has been projected\n",
    "onto the set of instruments in the IV model\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value from the chi-squared test is small (typically below a chosen significance level like 0.05), it suggests that the null hypothesis of no systematic difference between the OLS and IV coefficient estimates should be rejected. In this case, there is evidence of endogeneity, indicating that the OLS estimates are biased and inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stage\n",
    "X = sm.add_constant(np.column_stack((X1, instrument))) #Add a column of ones to an array (in this case adding columns X1 and IV)\n",
    "model_first_stage = sm.OLS(X2, X).fit()\n",
    "X2_hat = model_first_stage.predict(X)  # Predicted values of X2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.522</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.522</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5464.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Sep 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:42:00</td>     <th>  Log-Likelihood:    </th> <td> -23258.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>4.652e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9997</td>      <th>  BIC:               </th> <td>4.654e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9876</td> <td>    0.025</td> <td>   39.869</td> <td> 0.000</td> <td>    0.939</td> <td>    1.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.0259</td> <td>    0.025</td> <td>   82.057</td> <td> 0.000</td> <td>    1.978</td> <td>    2.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.0522</td> <td>    0.048</td> <td>   63.319</td> <td> 0.000</td> <td>    2.958</td> <td>    3.147</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.316</td> <th>  Durbin-Watson:     </th> <td>   1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.191</td> <th>  Jarque-Bera (JB):  </th> <td>   3.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.914</td> <th>  Cond. No.          </th> <td>    1.95</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.522   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.522   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5464.   \\\\\n",
       "\\textbf{Date:}             & Fri, 01 Sep 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     15:42:00     & \\textbf{  Log-Likelihood:    } &   -23258.   \\\\\n",
       "\\textbf{No. Observations:} &       10000      & \\textbf{  AIC:               } & 4.652e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        9997      & \\textbf{  BIC:               } & 4.654e+04   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.9876  &        0.025     &    39.869  &         0.000        &        0.939    &        1.036     \\\\\n",
       "\\textbf{x1}    &       2.0259  &        0.025     &    82.057  &         0.000        &        1.978    &        2.074     \\\\\n",
       "\\textbf{x2}    &       3.0522  &        0.048     &    63.319  &         0.000        &        2.958    &        3.147     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.316 & \\textbf{  Durbin-Watson:     } &    1.995  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.191 & \\textbf{  Jarque-Bera (JB):  } &    3.159  \\\\\n",
       "\\textbf{Skew:}          &  0.007 & \\textbf{  Prob(JB):          } &    0.206  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.914 & \\textbf{  Cond. No.          } &     1.95  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.522\n",
       "Model:                            OLS   Adj. R-squared:                  0.522\n",
       "Method:                 Least Squares   F-statistic:                     5464.\n",
       "Date:                Fri, 01 Sep 2023   Prob (F-statistic):               0.00\n",
       "Time:                        15:42:00   Log-Likelihood:                -23258.\n",
       "No. Observations:               10000   AIC:                         4.652e+04\n",
       "Df Residuals:                    9997   BIC:                         4.654e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9876      0.025     39.869      0.000       0.939       1.036\n",
       "x1             2.0259      0.025     82.057      0.000       1.978       2.074\n",
       "x2             3.0522      0.048     63.319      0.000       2.958       3.147\n",
       "==============================================================================\n",
       "Omnibus:                        3.316   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.191   Jarque-Bera (JB):                3.159\n",
       "Skew:                           0.007   Prob(JB):                        0.206\n",
       "Kurtosis:                       2.914   Cond. No.                         1.95\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second stage\n",
    "X_main = sm.add_constant(np.column_stack((X1, X2_hat)))  #you obtain the predicted values of the endogenous variable based on the instrumental variables.\n",
    "model_second_stage = sm.OLS(Y, X_main).fit()\n",
    "second_stage_coef = model_second_stage.params[2]\n",
    "model_second_stage.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information and how we should do Hausman Test, please refer to this Wikipedia page: https://en.wikipedia.org/wiki/Durbin%E2%80%93Wu%E2%80%93Hausman_test. After we calculated the test statistics, we can go to the Chi-square distribution table and find out the p-value. We can reject the null hypothesis if the test result is statistically significant and conclude that there is endogeneity problem exists in this model. We can also do the test using another package linearmodels.iv.model, for more information, please check this page: https://www.datascienceconcepts.com/tutorials/python-programming-language/exogeneity-wu-hausman-and-sargan-tests-in-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute test statistic\n",
    "# test_statistic = (orig_coef - second_stage_coef) * (1 / (model_second_stage.bse[2]**2) - (model_original.bse[2]**2)) * (orig_coef - second_stage_coef)\n",
    "\n",
    "# # Compute the p-value\n",
    "# p_value = 1 - stats.chi2.cdf(test_statistic, 1)\n",
    "# print(\"Test Statistic:\", test_statistic)\n",
    "# print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
